import openai
from fastapi import FastAPI, File, UploadFile, HTTPException, Form, BackgroundTasks, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import os
import io
import time
import uuid
import httpx
import redis
import logging
from typing import Optional, List, Dict, Any
import json
import numpy as np
import cv2
import asyncio
import traceback
import csv
import random

# Th√™m import cho static frontend
from static_frontend import mount_static_frontend

# C·∫•u h√¨nh OpenAI API key
OPENAI_API_KEY = "API key"
openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o FastAPI
app = FastAPI(title="OCR Pipeline API")

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# K·∫øt n·ªëi Redis
redis_host = os.environ.get("REDIS_HOST", "localhost")
redis_client = redis.Redis(host=redis_host, port=6379, db=0)

# Service URLs t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
PREPROCESSING_URL = os.environ.get("PREPROCESSING_URL", "http://preprocessing:5000")
DOCTR_URL = os.environ.get("DOCTR_URL", "http://doctr:5001")
TROCR_URL = os.environ.get("TROCR_URL", "http://trocr:5002")
MMOCR_URL = os.environ.get("MMOCR_URL", "http://mmocr:5003")

# C·∫•u h√¨nh timeout - TƒÉng l√™n ƒë·ªÉ x·ª≠ l√Ω OCR v·ªõi nhi·ªÅu v√πng vƒÉn b·∫£n
REQUEST_TIMEOUT = 180.0  # TƒÉng timeout l√™n 180 gi√¢y

# Mount frontend HTML
mount_static_frontend(app)

# Model definitions
class OCRRequest(BaseModel):
    image_id: str
    model: str = "doctr"  # Default model

class OCRResponse(BaseModel):
    job_id: str
    status: str
    result: Optional[List[Dict[str, Any]]] = None
    error: Optional[str] = None

class GPTRequest(BaseModel):
    extracted_text: str
    prompt: Optional[str] = None

# H√†m ti·ªán √≠ch retry cho c√°c HTTP request
async def fetch_with_retry(client, method, url, **kwargs):
    """Th·ª±c hi·ªán HTTP request v·ªõi c∆° ch·∫ø retry khi l·ªói v√† health check."""
    max_retries = 8  # Increased max retries
    initial_delay = 5  # Increased initial delay
    max_delay = 60  # Increased max delay
    last_exception = None
    service_name = url.split("//")[1].split(":")[0]
    
    # Avoid unnecessary health checks on subsequent attempts
    health_check_attempted = False
    
    for attempt in range(max_retries):
        try:
            # Try health check first for services we know about, but only on first attempt
            if not health_check_attempted and any(service in url for service in ["preprocessing", "doctr", "trocr", "mmocr"]):
                try:
                    health_check_attempted = True
                    # Get base URL for health check
                    base_url = url.split("/")[0] + "//" + url.split("/")[2]
                    health_url = f"{base_url}/health"
                    logger.info(f"Checking health for {service_name} at {health_url}")
                    
                    health_timeout = 10.0  # Increased timeout for health check
                    health_response = await client.get(health_url, timeout=health_timeout)
                    
                    if health_response.status_code == 200:
                        logger.info(f"Health check passed for {service_name}")
                    else:
                        logger.warning(f"Health check failed for {service_name} with status code {health_response.status_code}")
                except Exception as e:
                    logger.warning(f"Health check failed for {service_name}: {str(e)}")
            
            # Add longer timeout for the main request
            if 'timeout' not in kwargs:
                kwargs['timeout'] = 60.0

            # Main request
            if method.lower() == "get":
                response = await client.get(url, **kwargs)
            elif method.lower() == "post":
                response = await client.post(url, **kwargs)
            else:
                raise ValueError(f"Unsupported HTTP method: {method}")
            
            if response.status_code >= 400:
                logger.warning(f"Request failed with status {response.status_code} for {service_name}: {response.text}")
                if response.status_code >= 500:
                    raise httpx.HTTPError(f"Server error: {response.status_code}")
                return response
                
            return response
            
        except (httpx.ConnectError, httpx.ReadTimeout, httpx.ConnectTimeout, 
                httpx.WriteTimeout, httpx.PoolTimeout, httpx.NetworkError,
                httpx.ProxyError, httpx.HTTPError) as e:
            last_exception = e
            
            # Use exponential backoff with initial delay
            delay = min(max_delay, initial_delay * (2 ** attempt) + random.uniform(0, 1))
            
            logger.warning(
                f"Connection to {service_name} failed (attempt {attempt+1}/{max_retries}): {str(e)}. "
                f"Retrying in {delay:.2f} seconds..."
            )
            
            if attempt == max_retries - 1:
                logger.error(
                    f"All {max_retries} attempts failed for {service_name}. "
                    f"Make sure the service is running and healthy. Error: {str(e)}"
                )
                raise httpx.ConnectError(
                    f"Could not connect to {service_name} after {max_retries} attempts. "
                    "Please check if the service is running."
                ) from e
                
            await asyncio.sleep(delay)
    
    raise last_exception if last_exception else RuntimeError("Unknown error in fetch_with_retry")

# Function to chat with GPT
def chat_with_gpt(extracted_text: str, image_name: str = "", prompt: Optional[str] = None):
    structured_prompt = """
B·∫°n h√£y ph√¢n t√≠ch v√† tr√¨nh b√†y th√¥ng tin v·ªÅ m·ªôt s·∫£n ph·∫©m d∆∞·ª°ng da d·ª±a tr√™n danh s√°ch th√†nh ph·∫ßn m√† t√¥i cung c·∫•p. K·∫øt qu·∫£ c·∫ßn chia th√†nh 4 ph·∫ßn r√µ r√†ng nh∆∞ sau:

# 1. TH√ÄNH PH·∫¶N CH√çNH 
Li·ªát k√™ t·∫•t c·∫£ t·ª´ng th√†nh ph·∫ßn c√≥ trong danh s√°ch, m·ªói d√≤ng g·ªìm:  
[T√™n th√†nh ph·∫ßn] ‚Äì [Gi·∫£i th√≠ch ng·∫Øn g·ªçn c√¥ng d·ª•ng ch√≠nh, ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu].  
Gi·∫£i th√≠ch n√™n ∆∞u ti√™n t√°c d·ª•ng ph·ªï bi·∫øn v√† ƒë∆°n gi·∫£n h√≥a t·ª´ chuy√™n m√¥n ph·ª©c t·∫°p n·∫øu c√≥.

# 2. C√îNG D·ª§NG CH√çNH
T√≥m t·∫Øt 4‚Äì6 c√¥ng d·ª•ng n·ªïi b·∫≠t c·ªßa s·∫£n ph·∫©m d∆∞·ªõi d·∫°ng bullet point bi·ªÉu t∆∞·ª£ng nh∆∞ sau:  

üåü L√†m s√°ng da  
üíß D∆∞·ª°ng ·∫©m  
üß¥ Ch·ªëng l√£o h√≥a  
üõ°Ô∏è TƒÉng c∆∞·ªùng h√†ng r√†o b·∫£o v·ªá da  
üßò‚Äç‚ôÄÔ∏è L√†m d·ªãu v√† m·ªÅm da  

(Ch·ªçn v√† di·ªÖn gi·∫£i t√πy thu·ªôc v√†o th√†nh ph·∫ßn th·∫≠t s·ª± c√≥)

# 3. PH√ô H·ª¢P V·ªöI LO·∫†I DA N√ÄO  
G·ªìm c√°c lo·∫°i da ph·ªï bi·∫øn: Da kh√¥, Da th∆∞·ªùng, Da h·ªón h·ª£p, Da d·∫ßu, Da nh·∫°y c·∫£m.  
V·ªõi m·ªói lo·∫°i, ƒë√°nh d·∫•u b·∫±ng ‚úÖ (ph√π h·ª£p), ‚ö†Ô∏è (c·∫ßn c√¢n nh·∫Øc), ho·∫∑c ‚ùå (kh√¥ng ph√π h·ª£p).  
Gi·∫£i th√≠ch ng·∫Øn g·ªçn l√Ω do ph√π h·ª£p hay kh√¥ng, d·ª±a v√†o th√†nh ph·∫ßn s·∫£n ph·∫©m.

# 4. C·∫¢NH B√ÅO & L∆ØU √ù  
N·∫øu trong th√†nh ph·∫ßn c√≥ c√°c ho·∫°t ch·∫•t d·ªÖ g√¢y k√≠ch ·ª©ng nh∆∞ Retinol, AHA, BHA,... h√£y th√™m c·∫£nh b√°o.  
G·ª£i √Ω m·ªôt s·ªë c·∫£nh b√°o ph·ªï bi·∫øn:  

‚ö†Ô∏è C√≥ th·ªÉ g√¢y k√≠ch ·ª©ng n·∫øu da nh·∫°y c·∫£m ho·∫∑c l·∫ßn ƒë·∫ßu d√πng  
‚òÄÔ∏è C·∫ßn d√πng kem ch·ªëng n·∫Øng ban ng√†y  
‚ùå Kh√¥ng k·∫øt h·ª£p v·ªõi c√°c s·∫£n ph·∫©m AHA/BHA n·ªìng ƒë·ªô cao  
üß™ N√™n test v√πng da nh·ªè tr∆∞·ªõc khi d√πng to√†n m·∫∑t

H√£y tr√¨nh b√†y r√µ r√†ng, g·ªçn g√†ng, ƒë√∫ng format, d·ªÖ ƒë·ªçc. Ch·ªâ ƒë∆∞a ra th√¥ng tin theo ƒë√∫ng 4 ph·∫ßn tr√™n. ƒê·ª´ng th√™m l·ªùi khuy√™n, gi·ªõi thi·ªáu ho·∫∑c t·ªïng k·∫øt th·ª´a. S·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng Markdown ƒë√∫ng c√°ch v·ªõi ti√™u ƒë·ªÅ (#) v√† kho·∫£ng c√°ch h·ª£p l√Ω gi·ªØa c√°c ph·∫ßn.
"""
    
    # user_prompt = prompt if prompt else structured_prompt
    
    response = openai_client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": "You are a helpful skincare analysis assistant."},
            {"role": "user", "content": extracted_text + "\n\n" + structured_prompt}
        ],
        temperature=0.7,
    )
    
    response_text = response.choices[0].message.content
    
    # Tr·∫£ v·ªÅ vƒÉn b·∫£n ƒë·ªãnh d·∫°ng Markdown tr·ª±c ti·∫øp, kh√¥ng c·∫ßn ph√¢n t√≠ch JSON
    return response_text

@app.post("/analyze-with-gpt/")
async def analyze_with_gpt(request: GPTRequest):
    """
    Analyze extracted text using GPT model
    """
    try:
        # S·ª≠ d·ª•ng prompt ƒë√£ c·∫≠p nh·∫≠t trong h√†m chat_with_gpt
        analysis = chat_with_gpt(request.extracted_text, prompt=request.prompt)
        
        # Tr·∫£ v·ªÅ ph·∫£n h·ªìi ƒë·ªãnh d·∫°ng Markdown tr·ª±c ti·∫øp
        return {"response": analysis}
    except Exception as e:
        logger.error(f"Error calling GPT API: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error analyzing text: {str(e)}")

# API endpoints
@app.post("/upload-image/")
async def upload_image(file: UploadFile = File(...)):
    """
    Upload an image for processing.
    Returns an image_id that can be used to request OCR processing.
    """
    try:
        # ƒê·ªçc n·ªôi dung h√¨nh ·∫£nh
        contents = await file.read()
        
        # T·∫°o ID duy nh·∫•t cho h√¨nh ·∫£nh
        image_id = str(uuid.uuid4())
        
        # L∆∞u h√¨nh ·∫£nh v√†o Redis (th·ªùi h·∫°n 30 ph√∫t)
        redis_client.set(f"image:{image_id}", contents, ex=1800)
        
        # L∆∞u th√™m t√™n file g·ªëc v√†o Redis
        redis_client.set(f"image_filename:{image_id}", file.filename, ex=1800)
        
        return {"image_id": image_id, "filename": file.filename}
    
    except Exception as e:
        logger.error(f"Error uploading image: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error uploading image: {str(e)}")

@app.post("/process/", response_model=OCRResponse)
async def process_image(background_tasks: BackgroundTasks, request: OCRRequest):
    """
    Process an uploaded image with the specified OCR model.
    """
    # Ki·ªÉm tra model
    if request.model.lower() not in ["doctr", "trocr", "mmocr"]:
        raise HTTPException(status_code=400, detail="Invalid model selection. Choose 'doctr', 'trocr', or 'mmocr'")
    
    # Ki·ªÉm tra h√¨nh ·∫£nh c√≥ t·ªìn t·∫°i kh√¥ng
    if not redis_client.exists(f"image:{request.image_id}"):
        raise HTTPException(status_code=404, detail="Image not found. Please upload the image first.")
    
    # T·∫°o job ID
    job_id = str(uuid.uuid4())
    
    # L∆∞u tr·∫°ng th√°i job v√†o Redis
    redis_client.hset(
        f"job:{job_id}",
        mapping={
            "status": "pending",
            "image_id": request.image_id,
            "model": request.model,
            "created_at": time.time()
        }
    )
    redis_client.expire(f"job:{job_id}", 3600)  # H·∫øt h·∫°n sau 1 gi·ªù
    
    # Kh·ªüi ƒë·ªông x·ª≠ l√Ω background
    background_tasks.add_task(process_image_task, job_id, request.image_id, request.model)
    
    return {"job_id": job_id, "status": "pending"}

@app.get("/status/{job_id}", response_model=OCRResponse)
async def get_job_status(job_id: str):
    """
    Check the status of an OCR processing job.
    """
    # Ki·ªÉm tra job c√≥ t·ªìn t·∫°i kh√¥ng
    if not redis_client.exists(f"job:{job_id}"):
        raise HTTPException(status_code=404, detail="Job not found")
    
    # L·∫•y tr·∫°ng th√°i job
    job_data = redis_client.hgetall(f"job:{job_id}")
    
    # Chuy·ªÉn t·ª´ byte sang string
    job_data = {k.decode('utf-8'): v.decode('utf-8') for k, v in job_data.items()}
    
    response = {"job_id": job_id, "status": job_data["status"]}
    
    if job_data["status"] == "completed":
        # L·∫•y k·∫øt qu·∫£ t·ª´ Redis
        result_json = redis_client.get(f"result:{job_id}")
        if result_json:
            response["result"] = json.loads(result_json)
    
    elif job_data["status"] == "failed":
        response["error"] = job_data.get("error", "Unknown error")
    
    return response
    
@app.get("/models")
async def list_models():
    """
    List available OCR models
    """
    return {
        "models": [
            {"id": "doctr", "name": "DocTR", "description": "Document Text Recognition model"},
            {"id": "trocr", "name": "TrOCR", "description": "Transformer-based OCR model"},
            {"id": "mmocr", "name": "MMOCR", "description": "OpenMMLab Text Detection and Recognition"}
        ]
    }

# Background task to process the image
# Background task to process the image
async def process_image_task(job_id: str, image_id: str, model: str):
    """
    Background task to process an image through the OCR pipeline.
    """
    try:
        # C·∫≠p nh·∫≠t tr·∫°ng th√°i job
        redis_client.hset(f"job:{job_id}", "status", "processing")
        
        # L·∫•y d·ªØ li·ªáu h√¨nh ·∫£nh t·ª´ Redis
        image_data = redis_client.get(f"image:{image_id}")
        if not image_data:
            raise Exception("Image data not found in Redis")
        
        # L·∫•y t√™n file g·ªëc t·ª´ Redis
        original_filename = redis_client.get(f"image_filename:{image_id}")
        if original_filename:
            original_filename = original_filename.decode('utf-8')
            # L∆∞u t√™n file g·ªëc v√†o job data
            redis_client.hset(f"job:{job_id}", "original_filename", original_filename)
        
        # Step 1: G·ª≠i h√¨nh ·∫£nh ƒë·∫øn preprocessing service
        logger.info(f"Sending image {image_id} to preprocessing service")
        
        # Create client with increased timeout
        async with httpx.AsyncClient(timeout=REQUEST_TIMEOUT) as client:
            # Step 1: Preprocessing
            preprocessed_image_id = None
            preprocessing_attempts = 0
            max_preprocessing_attempts = 3
            
            while preprocessing_attempts < max_preprocessing_attempts:
                try:
                    preprocessing_attempts += 1
                    logger.info(f"Preprocessing attempt {preprocessing_attempts}/{max_preprocessing_attempts}")
                    
                    preprocessing_response = await fetch_with_retry(
                        client, 
                        "post",
                        f"{PREPROCESSING_URL}/preprocess",
                        files={"file": ("image.jpg", image_data)},
                        timeout=REQUEST_TIMEOUT
                    )
                    
                    if preprocessing_response.status_code != 200:
                        error_msg = f"Preprocessing failed: {preprocessing_response.text}"
                        logger.error(error_msg)
                        if preprocessing_attempts >= max_preprocessing_attempts:
                            raise Exception(error_msg)
                        await asyncio.sleep(5)  # Wait before retry
                        continue
                    
                    # L·∫•y ID ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω
                    preprocessed_image_id = preprocessing_response.json()["preprocessed_image_id"]
                    
                    # L∆∞u ID ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω v√†o job
                    redis_client.hset(f"job:{job_id}", "preprocessed_image_id", preprocessed_image_id)
                    logger.info(f"Preprocessing successful, image ID: {preprocessed_image_id}")
                    break
                    
                except Exception as e:
                    logger.error(f"Preprocessing error: {str(e)}")
                    if preprocessing_attempts >= max_preprocessing_attempts:
                        raise Exception(f"Preprocessing failed after {max_preprocessing_attempts} attempts: {str(e)}")
                    await asyncio.sleep(5)  # Wait before retry
            
            if not preprocessed_image_id:
                raise Exception("Failed to preprocess image after multiple attempts")
            
            # Step 2: Send to appropriate OCR service
            ocr_url = {
                "doctr": f"{DOCTR_URL}/recognize",
                "trocr": f"{TROCR_URL}/recognize",
                "mmocr": f"{MMOCR_URL}/recognize"
            }[model.lower()]
            
            logger.info(f"Sending preprocessed image to {model} service")
            
            # Longer timeout for TrOCR
            request_timeout = REQUEST_TIMEOUT * 2 if model.lower() == "trocr" else REQUEST_TIMEOUT
            
            # OCR processing with retries
            ocr_attempts = 0
            max_ocr_attempts = 3
            
            while ocr_attempts < max_ocr_attempts:
                try:
                    ocr_attempts += 1
                    logger.info(f"OCR attempt {ocr_attempts}/{max_ocr_attempts} with {model} service")
                    
                    ocr_response = await fetch_with_retry(
                        client,
                        "post",
                        ocr_url,
                        json={"preprocessed_image_id": preprocessed_image_id},
                        timeout=request_timeout
                    )
                    
                    if ocr_response.status_code != 200:
                        error_msg = f"OCR processing failed: {ocr_response.text}"
                        logger.error(error_msg)
                        if ocr_attempts >= max_ocr_attempts:
                            raise Exception(error_msg)
                        await asyncio.sleep(5)  # Wait before retry
                        continue
                    
                    # Parse result
                    result = None
                    try:
                        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p response.text c√≥ th·ªÉ l√† thu·ªôc t√≠nh ho·∫∑c ph∆∞∆°ng th·ª©c
                        if hasattr(ocr_response, 'text'):
                            if callable(ocr_response.text):
                                # N·∫øu l√† ph∆∞∆°ng th·ª©c
                                try:
                                    result_text = await ocr_response.text()
                                    result = json.loads(result_text)
                                except TypeError:
                                    # N·∫øu ocr_response.text kh√¥ng ph·∫£i callable
                                    if isinstance(ocr_response.text, str):
                                        result = json.loads(ocr_response.text)
                                    else:
                                        # Tr∆∞·ªùng h·ª£p kh√°c
                                        result = ocr_response.json()
                            else:
                                # N·∫øu l√† thu·ªôc t√≠nh
                                if isinstance(ocr_response.text, str):
                                    result = json.loads(ocr_response.text)
                                else:
                                    # Tr∆∞·ªùng h·ª£p kh√°c
                                    result = ocr_response.json()
                        else:
                            # Tr·∫£ v·ªÅ tr·ª±c ti·∫øp
                            result = ocr_response.json()
                        
                        print(f"OCR response structure: {list(result.keys()) if isinstance(result, dict) else 'Not a dictionary'}")
                        
                    except Exception as e:
                        logger.error(f"Error parsing OCR response: {str(e)}")
                        traceback.print_exc()
                        if ocr_attempts >= max_ocr_attempts:
                            raise Exception(f"Error parsing OCR response: {str(e)}")
                        await asyncio.sleep(5)  # Wait before retry
                        continue
                    
                    if not isinstance(result, dict) or "result" not in result:
                        error_msg = f"Invalid OCR response format: {result}"
                        logger.error(error_msg)
                        if ocr_attempts >= max_ocr_attempts:
                            raise Exception(error_msg)
                        await asyncio.sleep(5)  # Wait before retry
                        continue
                    
                    # Log details about the result
                    print(f"Result contains {len(result['result'])} text regions")
                    if result['result'] and len(result['result']) > 0:
                        print(f"First result item: {result['result'][0]}")
                    
                    # Save result to Redis with longer expiration (2 hours)
                    redis_client.set(f"result:{job_id}", json.dumps(result["result"]), ex=7200)
                    print(f"Saved results to Redis with key: result:{job_id}")
                    
                    # Update job status to completed
                    redis_client.hset(f"job:{job_id}", "status", "completed")
                    logger.info(f"Job {job_id} completed successfully with {model} OCR service")
                    return
                    
                except Exception as e:
                    logger.error(f"OCR error with {model} service: {str(e)}")
                    if ocr_attempts >= max_ocr_attempts:
                        raise Exception(f"OCR processing failed after {max_ocr_attempts} attempts: {str(e)}")
                    await asyncio.sleep(5)  # Wait before retry
            
            # If we got here without returning, all attempts failed
            raise Exception(f"All OCR attempts with {model} service failed")
    
    except Exception as e:
        logger.error(f"Error processing job {job_id}: {str(e)}")
        logger.error(traceback.format_exc())
        # Store detailed error information in Redis
        redis_client.hset(
            f"job:{job_id}",
            mapping={
                "status": "failed",
                "error": str(e),
                "error_time": time.time()
            }
        )
        # Set expiration for failed jobs (1 hour)
        redis_client.expire(f"job:{job_id}", 3600)

@app.get("/annotated-image/{job_id}")
async def get_annotated_image(job_id: str):
    """
    Return the preprocessed image with bounding boxes drawn on it
    """
    try:
        logger.info(f"Annotation request received for job_id: {job_id}")
        
        # Ki·ªÉm tra job c√≥ t·ªìn t·∫°i kh√¥ng
        if not redis_client.exists(f"job:{job_id}"):
            logger.error(f"Job ID not found: {job_id}")
            raise HTTPException(status_code=404, detail="Job not found")
        
        # L·∫•y th√¥ng tin job
        job_data = redis_client.hgetall(f"job:{job_id}")
        job_data = {k.decode('utf-8'): v.decode('utf-8') for k, v in job_data.items()}
        logger.info(f"Job data: {job_data}")
        
        if job_data["status"] != "completed":
            raise HTTPException(status_code=400, detail="Job not completed yet")
        
        # L·∫•y model ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ bi·∫øt k√≠ch th∆∞·ªõc resize
        model = job_data.get("model", "doctr").lower()
        
        # L·∫•y ID ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω t·ª´ job
        preprocessed_image_id = job_data.get("preprocessed_image_id")
        if not preprocessed_image_id:
            # Log the error and provide a detailed message
            logger.error(f"Preprocessed image ID not found for job {job_id}")
            raise HTTPException(status_code=404, detail="Preprocessed image ID not found in job data. The preprocessing step may have failed.")
        
        # L·∫•y ·∫£nh ƒë√£ ti·ªÅn x·ª≠ l√Ω t·ª´ Redis
        preprocessed_image_bytes = redis_client.get(f"preprocessed:{preprocessed_image_id}")
        if not preprocessed_image_bytes:
            logger.error(f"Preprocessed image not found in Redis for ID: {preprocessed_image_id}")
            # Attempt to recover with alternative methods (if available)
            original_image_id = job_data.get("image_id")
            if original_image_id:
                logger.info(f"Attempting to fall back to original image {original_image_id}")
                original_image_bytes = redis_client.get(f"image:{original_image_id}")
                if original_image_bytes:
                    preprocessed_image_bytes = original_image_bytes
                    logger.info("Successfully retrieved original image as fallback")
                else:
                    logger.error(f"Original image also not found for ID: {original_image_id}")
                    raise HTTPException(status_code=404, detail="Preprocessed image not found in storage. The data may have expired.")
            else:
                raise HTTPException(status_code=404, detail="Preprocessed image not found in storage. The data may have expired.")
        
        # Chuy·ªÉn ƒë·ªïi sang numpy array
        try:
            nparr = np.frombuffer(preprocessed_image_bytes, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                logger.error("Failed to decode image from bytes")
                raise HTTPException(status_code=500, detail="Failed to decode image data")
                
            # Log image dimensions for debugging
            logger.info(f"Decoded image dimensions: {img.shape}")
        except Exception as e:
            logger.error(f"Error decoding image: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Error decoding image: {str(e)}")
        
        # K√≠ch th∆∞·ªõc resize d·ª±a tr√™n model
        if model == "mmocr":
            resize_width, resize_height = 640, 640
        else:  # DocTR ho·∫∑c TrOCR ƒë·ªÅu d√πng 1024
            resize_width, resize_height = 1024, 1024
        
        # Tr√≠ch xu·∫•t k√≠ch th∆∞·ªõc th·ª±c t·∫ø c·ªßa ·∫£nh ƒë·ªÉ bi·∫øt t·ª∑ l·ªá
        actual_height, actual_width = img.shape[:2]
        
        # L·∫•y k·∫øt qu·∫£ OCR ƒë·ªÉ v·∫Ω bounding box
        result_json = redis_client.get(f"result:{job_id}")
        if not result_json:
            logger.error(f"OCR result not found for job_id: {job_id}")
            raise HTTPException(status_code=404, detail="OCR result not found. The result may have expired or the OCR process failed.")
        
        try:
            result = json.loads(result_json)
            logger.info(f"Drawing {len(result)} bounding boxes")
        except json.JSONDecodeError as e:
            logger.error(f"Error parsing OCR result JSON: {str(e)}")
            raise HTTPException(status_code=500, detail="Invalid OCR result format")
        
        # Create a copy of the image for drawing
        draw_img = img.copy()
        
        # V·∫Ω bounding box l√™n ·∫£nh
        drawn_boxes = 0
        for item in result:
            if "bbox" in item and item["bbox"]:  # Ki·ªÉm tra bbox kh√¥ng r·ªóng
                bbox = item["bbox"]
                text = item.get("text", "")
                
                # ƒê·∫£m b·∫£o ƒë·ªãnh d·∫°ng bbox h·ª£p l·ªá
                if bbox and isinstance(bbox, list) and len(bbox) >= 4:
                    try:
                        # Ghi log ƒë·ªÉ debug
                        logger.info(f"Drawing bbox: {bbox}")
                        
                        # Chuy·ªÉn ƒë·ªïi th√†nh numpy array
                        bbox_np = np.array(bbox, np.int32)
                        
                        # ƒê·∫£m b·∫£o bbox_np c√≥ ƒë·ªß ƒëi·ªÉm v√† ƒë√∫ng ƒë·ªãnh d·∫°ng
                        if bbox_np.shape[0] >= 4:
                            # FIX: ƒê·∫£m b·∫£o reshape ƒë√∫ng ƒë·ªãnh d·∫°ng m√† OpenCV y√™u c·∫ßu
                            bbox_np = bbox_np.reshape((-1, 1, 2))
                            
                            # V·∫Ω ƒë∆∞·ªùng vi·ªÅn (ƒë·ªè)
                            cv2.polylines(draw_img, [bbox_np], True, (0, 0, 255), 2)
                            drawn_boxes += 1
                            
                            # V·∫Ω text
                            if len(bbox) > 0:
                                # L·∫•y t·ªça ƒë·ªô g√≥c tr√™n b√™n tr√°i ƒë·ªÉ v·∫Ω text
                                x, y = bbox[0]
                                # ƒê·∫∑t text ·ªü v·ªã tr√≠ ph√π h·ª£p, tr√°nh ra ngo√†i ·∫£nh
                                x = max(0, x)
                                y = max(20, y)  # ƒê·∫£m b·∫£o ƒë·ªß kh√¥ng gian cho text
                                # Use a better font scale based on image size
                                font_scale = max(0.3, min(1.0, actual_width / 1000))
                                cv2.putText(draw_img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), 1)
                        else:
                            logger.warning(f"Skipping bbox with insufficient points: {bbox}")
                    except Exception as e:
                        logger.error(f"Error drawing bbox: {e}")
                        traceback.print_exc()  # Th√™m d√≤ng n√†y ƒë·ªÉ ghi chi ti·∫øt l·ªói
        
        logger.info(f"Successfully drew {drawn_boxes} bounding boxes out of {len(result)} results")
        
        try:
            # Chuy·ªÉn ƒë·ªïi ·∫£nh th√†nh byte stream
            success, processed_bytes = cv2.imencode('.png', draw_img)
            
            # Ki·ªÉm tra k·∫øt qu·∫£ encoding
            if not success:
                logger.error("Failed to encode annotated image")
                raise HTTPException(status_code=500, detail="Error encoding image")
                
            buffer = processed_bytes.tobytes()
            
            # Tr·∫£ v·ªÅ ·∫£nh
            return StreamingResponse(io.BytesIO(buffer), media_type="image/png")
        except Exception as e:
            logger.error(f"Error creating image response: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Error creating image response: {str(e)}")
    
    except HTTPException:
        # Re-raise HTTP exceptions without modification
        raise
    except Exception as e:
        logger.error(f"Error generating annotated image: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@app.get("/export-csv/{job_id}")
async def export_csv(job_id: str):
    """Export OCR and analysis results to CSV"""
    try:
        # Get OCR result
        ocr_result = redis_client.get(f"result:{job_id}")
        if not ocr_result:
            raise HTTPException(status_code=404, detail="Result not found")
            
        # Get image name
        job_info = redis_client.hgetall(f"job:{job_id}")
        image_id = job_info.get(b"image_id").decode("utf-8")

        # L·∫•y t√™n file g·ªëc t·ª´ job data
        original_filename = job_info.get(b"original_filename")
        if original_filename:
            original_filename = original_filename.decode("utf-8")
        else:
            # N·∫øu kh√¥ng c√≥ t√™n file g·ªëc, s·ª≠ d·ª•ng image_id
            original_filename = image_id
        
        # Extract text
        result_data = json.loads(ocr_result)
        extracted_text = "\n".join([item["text"] for item in result_data])
        
        # Get GPT analysis
        gpt_response = chat_with_gpt(extracted_text, image_id)
        
        # Ph√¢n t√≠ch n·ªôi dung t·ª´ ƒë·ªãnh d·∫°ng Markdown ƒë·ªÉ xu·∫•t CSV
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho CSV
        ingredients_list = ""
        benefits_list = ""
        skin_types_list = ""
        warnings_list = ""
        
        # Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n ph·∫£n h·ªìi th√†nh c√°c ph·∫ßn ri√™ng bi·ªát
        import re
        
        # T√°ch ph·∫£n h·ªìi th√†nh t·ª´ng d√≤ng
        lines = gpt_response.split('\n')
        current_section = None
        
        # X√°c ƒë·ªãnh c√°c m·∫´u ti√™u ƒë·ªÅ cho t·ª´ng ph·∫ßn
        sections_patterns = {
            "ingredients": ["TH√ÄNH PH·∫¶N CH√çNH", "INGREDIENTS"],
            "benefits": ["C√îNG D·ª§NG CH√çNH", "BENEFITS"],
            "skin_types": ["PH√ô H·ª¢P V·ªöI LO·∫†I DA N√ÄO", "SKIN_TYPES"],
            "warnings": ["C·∫¢NH B√ÅO & L∆ØU √ù", "WARNINGS", "C·∫¢NH B√ÅO V√Ä L∆ØU √ù"]
        }
        
        section_content = {
            "ingredients": [],
            "benefits": [],
            "skin_types": [],
            "warnings": []
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Ki·ªÉm tra xem d√≤ng hi·ªán t·∫°i c√≥ ph·∫£i l√† ti√™u ƒë·ªÅ kh√¥ng
            is_header = False
            for section, patterns in sections_patterns.items():
                if any(pattern.lower() in line.lower() for pattern in patterns):
                    current_section = section
                    is_header = True
                    break
            
            # N·∫øu kh√¥ng ph·∫£i ti√™u ƒë·ªÅ v√† thu·ªôc m·ªôt ph·∫ßn ƒë√£ bi·∫øt
            if not is_header and current_section:
                # Lo·∫°i b·ªè s·ªë th·ª© t·ª± n·∫øu c√≥ (nh∆∞ "1.", "2.")
                clean_line = re.sub(r'^\d+\.\s*', '', line)
                section_content[current_section].append(clean_line)
        
        # Chuy·ªÉn c√°c m·∫£ng th√†nh chu·ªói
        ingredients_list = "\n".join(section_content["ingredients"])
        benefits_list = "\n".join(section_content["benefits"])
        skin_types_list = "\n".join(section_content["skin_types"])
        warnings_list = "\n".join(section_content["warnings"])
        
        # L√†m s·∫°ch ƒë·ªãnh d·∫°ng Markdown
        # L√†m s·∫°ch ƒë·ªãnh d·∫°ng Markdown v√† emoji
        def clean_markdown_and_emoji(text):
            # X√≥a d·∫•u g·∫°ch ƒë·∫ßu d√≤ng v√† kho·∫£ng tr·∫Øng
            lines = []
            for line in text.split('\n'):
                line = line.strip()
                if line.startswith('- '):
                    line = line[2:]
                elif line.startswith('-'):
                    line = line[1:]
                elif line.startswith('* '):
                    line = line[2:]
                elif line.startswith('*'):
                    line = line[1:]
                
                # X√≥a c√°c ƒë·ªãnh d·∫°ng Markdown kh√°c
                line = re.sub(r'(\*\*|__)(.*?)(\*\*|__)', r'\2', line)  # Bold
                line = re.sub(r'(\*|_)(.*?)(\*|_)', r'\2', line)  # Italic
                line = re.sub(r'~~(.*?)~~', r'\1', line)  # Strikethrough
                line = re.sub(r'`(.*?)`', r'\1', line)  # Inline code
                line = re.sub(r'^#+\s*', '', line)  # Headers
                
                # X√≥a emoji th√¥ng d·ª•ng
                emoji_pattern = re.compile(
                    "["
                    "\U0001F1E0-\U0001F1FF"  # flags (iOS)
                    "\U0001F300-\U0001F5FF"  # symbols & pictographs
                    "\U0001F600-\U0001F64F"  # emoticons
                    "\U0001F680-\U0001F6FF"  # transport & map symbols
                    "\U0001F700-\U0001F77F"  # alchemical symbols
                    "\U0001F780-\U0001F7FF"  # Geometric Shapes
                    "\U0001F800-\U0001F8FF"  # Supplemental Arrows-C
                    "\U0001F900-\U0001F9FF"  # Supplemental Symbols and Pictographs
                    "\U0001FA00-\U0001FA6F"  # Chess Symbols
                    "\U0001FA70-\U0001FAFF"  # Symbols and Pictographs Extended-A
                    "\U00002702-\U000027B0"  # Dingbats
                    "\U000024C2-\U0001F251" 
                    "]+", flags=re.UNICODE)
                
                line = emoji_pattern.sub(r'', line)
                
                # X√≥a c√°c bi·ªÉu t∆∞·ª£ng ƒë√°nh d·∫•u c·ª• th·ªÉ
                line = line.replace('‚úÖ', '')  # ‚úÖ
                line = line.replace('‚ùå', '')  # ‚ùå
                line = line.replace('‚ö†Ô∏è', '')  # ‚ö†Ô∏è
                line = line.replace('‚òÄÔ∏è', '')  # ‚òÄÔ∏è
                line = line.replace('‚òë', '')  # ‚òë
                line = line.replace('‚úî', '')  # ‚úî
                
                # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
                line = re.sub(r'\s+', ' ', line).strip()
                
                if line.strip():
                    lines.append(line)
            return "\n".join(lines)
        
        # √Åp d·ª•ng l√†m s·∫°ch ƒë·ªãnh d·∫°ng v√† emoji
        ingredients_list = clean_markdown_and_emoji(ingredients_list)
        benefits_list = clean_markdown_and_emoji(benefits_list)
        skin_types_list = clean_markdown_and_emoji(skin_types_list)
        warnings_list = clean_markdown_and_emoji(warnings_list)
        
        # ƒê·∫£m b·∫£o kh√¥ng c√≥ c·ªôt n√†o tr·ªëng
        if not ingredients_list.strip():
            ingredients_list = "Kh√¥ng c√≥ th√¥ng tin v·ªÅ th√†nh ph·∫ßn"
        if not benefits_list.strip():
            benefits_list = "Kh√¥ng c√≥ th√¥ng tin v·ªÅ c√¥ng d·ª•ng"
        if not skin_types_list.strip():
            skin_types_list = "Kh√¥ng c√≥ th√¥ng tin v·ªÅ lo·∫°i da ph√π h·ª£p"
        if not warnings_list.strip():
            warnings_list = "Kh√¥ng c√≥ c·∫£nh b√°o"
        
        json_data = {
            "T√™n ·∫£nh": original_filename,
            "Th√†nh ph·∫ßn": ingredients_list,
            "C√¥ng d·ª•ng": benefits_list,
            "Da ph√π h·ª£p": skin_types_list,
            "L∆∞u √Ω": warnings_list
        }

        # Ghi log d·ªØ li·ªáu JSON
        with open("json_data.json", "a") as log_file:
            log_file.write(json.dumps(json_data, ensure_ascii=False) + "\n")

        # T·∫°o CSV in-memory
        output = io.StringIO()
        writer = csv.writer(output, quoting=csv.QUOTE_MINIMAL)
        writer.writerow(["T√™n ·∫£nh", "Th√†nh ph·∫ßn", "C√¥ng d·ª•ng", "Da ph√π h·ª£p", "L∆∞u √Ω"])
        writer.writerow([
            original_filename,
            ingredients_list,
            benefits_list,
            skin_types_list,
            warnings_list
        ])
        
        # L·∫•y n·ªôi dung chu·ªói v√† chuy·ªÉn th√†nh bytes v·ªõi encoding UTF-8
        csv_content = output.getvalue().encode('utf-8-sig')  # utf-8-sig bao g·ªìm BOM
        
        # T·∫°o BytesIO t·ª´ bytes
        bytes_io = io.BytesIO(csv_content)
        
        return StreamingResponse(
            bytes_io,
            media_type="text/csv; charset=utf-8",
            headers={"Content-Disposition": f"attachment; filename=analysis_{job_id}.csv"}
        )
        
    except Exception as e:
        logger.error(f"Error exporting CSV: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Error exporting CSV: {str(e)}")
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True) 
